{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/home/tt/imitation\")\n",
    "import argparse\n",
    "import json\n",
    "import h5py\n",
    "import numpy as np\n",
    "import yaml\n",
    "import os, os.path, shutil\n",
    "from policyopt import util\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def gen_taskname2outfile(spec, assert_not_exists=False):\n",
    "    '''\n",
    "    Generate dataset filenames for each task. Phase 0 (sampling) writes to these files,\n",
    "    phase 1 (training) reads from them.\n",
    "    '''\n",
    "    taskname2outfile = {}\n",
    "    trajdir = os.path.join(spec['options']['storagedir'], spec['options']['traj_subdir'])\n",
    "    util.mkdir_p(trajdir)\n",
    "    for task in spec['tasks']:\n",
    "        assert task['name'] not in taskname2outfile\n",
    "        fname = os.path.join(trajdir, 'trajs_{}.h5'.format(task['name']))\n",
    "        if assert_not_exists:\n",
    "            assert not os.path.exists(fname), 'Traj destination {} already exists'.format(fname)\n",
    "        taskname2outfile[task['name']] = fname\n",
    "    return taskname2outfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with open('./pipelines/im_pipeline.yaml', 'r') as f:\n",
    "    spec = yaml.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'options': {'checkpt_subdir': 'checkpoints_all',\n",
       "  'eval_num_trajs': 50,\n",
       "  'pbs': {'jobname': 'im_modern', 'ppn': 12, 'queue': 'atlas'},\n",
       "  'results_filename': 'results.h5',\n",
       "  'storagedir': 'imitation_runs/modern_stochastic',\n",
       "  'traj_subdir': 'trajs'},\n",
       " 'tasks': [{'cuts_off_on_success': False,\n",
       "   'data_subsamp_freq': 20,\n",
       "   'env': 'Hopper-v1',\n",
       "   'name': 'hopper',\n",
       "   'policy': 'expert_policies/modern/log_Hopper-v0_3.h5/snapshots/iter0000500'},\n",
       "  {'cuts_off_on_success': False,\n",
       "   'data_subsamp_freq': 20,\n",
       "   'env': 'Walker2d-v1',\n",
       "   'name': 'walker',\n",
       "   'policy': 'expert_policies/modern/walker_eb5b2e_1.h5/snapshots/iter0000480'},\n",
       "  {'cuts_off_on_success': False,\n",
       "   'data_subsamp_freq': 20,\n",
       "   'env': 'Ant-v1',\n",
       "   'name': 'ant',\n",
       "   'policy': 'expert_policies/modern/log_Ant-v1_0.h5/snapshots/iter0000500'},\n",
       "  {'cuts_off_on_success': False,\n",
       "   'data_subsamp_freq': 20,\n",
       "   'env': 'HalfCheetah-v1',\n",
       "   'name': 'halfcheetah',\n",
       "   'policy': 'expert_policies/modern/log_HalfCheetah-v0_2.h5/snapshots/iter0000500'}],\n",
       " 'training': {'algorithms': [{'cmd': 'python scripts/imitate_mj.py --mode bclone --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --max_iter 20001 --log {out}\\n',\n",
       "    'name': 'bclone'},\n",
       "   {'cmd': 'python scripts/imitate_mj.py --mode ga --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --favor_zero_expert_reward {cuts_off_on_success} --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log {out}\\n',\n",
       "    'name': 'ga'},\n",
       "   {'cmd': 'python scripts/imitate_mj.py --mode ga --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --favor_zero_expert_reward {cuts_off_on_success} --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log {out}\\n',\n",
       "    'name': 'fem'},\n",
       "   {'cmd': 'python scripts/imitate_mj.py --mode ga --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --favor_zero_expert_reward {cuts_off_on_success} --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log {out}\\n',\n",
       "    'name': 'simplex'}],\n",
       "  'dataset_num_trajs': [4, 11, 18, 25],\n",
       "  'deterministic_expert': False,\n",
       "  'full_dataset_num_trajs': 50,\n",
       "  'runs': 1}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "taskname2dset = gen_taskname2outfile(spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkptdir = os.path.join(spec['options']['storagedir'], spec['options']['checkpt_subdir'])\n",
    "util.mkdir_p(checkptdir)\n",
    "# Make sure checkpoint dir is empty\n",
    "assert not os.listdir(checkptdir), 'Checkpoint directory {} is not empty!'.format(checkptdir)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "cmd_templates, outputfilenames, argdicts = [], [], []\n",
    "for alg in spec['training']['algorithms']:\n",
    "    for task in spec['tasks']:\n",
    "        for num_trajs in spec['training']['dataset_num_trajs']:\n",
    "            assert num_trajs <= spec['training']['full_dataset_num_trajs']\n",
    "            for run in range(spec['training']['runs']):\n",
    "                # A string identifier. Used in filenames for this run\n",
    "                strid = 'alg={},task={},num_trajs={},run={}'.format(alg['name'], task['name'], num_trajs, run)\n",
    "                cmd_templates.append(alg['cmd'].replace('\\n', ' ').strip())\n",
    "                outputfilenames.append(strid + '.txt')\n",
    "                argdicts.append({\n",
    "                    'env': task['env'],\n",
    "                    'dataset': taskname2dset[task['name']],\n",
    "                    'num_trajs': num_trajs,\n",
    "                    'cuts_off_on_success': int(task['cuts_off_on_success']),\n",
    "                    'data_subsamp_freq': task['data_subsamp_freq'],\n",
    "                    'out': os.path.join(checkptdir, strid + '.h5'),\n",
    "                })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python scripts/imitate_mj.py --mode bclone --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 4 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=hopper,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 11 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=hopper,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 18 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=hopper,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 25 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=hopper,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 4 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=walker,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 11 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=walker,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 18 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=walker,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 25 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=walker,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 4 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=ant,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 11 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=ant,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 18 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=ant,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 25 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=ant,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 4 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=halfcheetah,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 11 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=halfcheetah,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 18 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=halfcheetah,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode bclone --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 25 --data_subsamp_freq 20 --max_iter 20001 --log imitation_runs/modern_stochastic/checkpoints_all/alg=bclone,task=halfcheetah,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=walker,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=walker,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=walker,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=walker,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=ant,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=ant,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=ant,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=ant,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=halfcheetah,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=halfcheetah,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=halfcheetah,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=halfcheetah,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=hopper,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=hopper,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=hopper,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=hopper,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=walker,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=walker,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=walker,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=walker,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=ant,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=ant,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=ant,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=ant,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=halfcheetah,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=halfcheetah,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=halfcheetah,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type l2ball --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=fem,task=halfcheetah,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=hopper,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=hopper,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=hopper,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=hopper,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=walker,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=walker,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=walker,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Walker2d-v1 --data imitation_runs/modern_stochastic/trajs/trajs_walker.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=walker,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=ant,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=ant,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=ant,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env Ant-v1 --data imitation_runs/modern_stochastic/trajs/trajs_ant.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=ant,num_trajs=25,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 4 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=halfcheetah,num_trajs=4,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 11 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=halfcheetah,num_trajs=11,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 18 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=halfcheetah,num_trajs=18,run=0.h5\n",
      "python scripts/imitate_mj.py --mode ga --env HalfCheetah-v1 --data imitation_runs/modern_stochastic/trajs/trajs_halfcheetah.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_type simplex --reward_include_time 0 --log imitation_runs/modern_stochastic/checkpoints_all/alg=simplex,task=halfcheetah,num_trajs=25,run=0.h5\n"
     ]
    }
   ],
   "source": [
    "for cmd, arg in zip(cmd_templates, argdicts):\n",
    "    print(cmd.format(**arg))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#!python scripts/imitate_mj.py --mode ga --env Hopper-v1 --data imitation_runs/modern_stochastic/trajs/trajs_hopper.h5 --limit_trajs 25 --data_subsamp_freq 20 --favor_zero_expert_reward 0 --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating results in imitation_runs/modern_stochastic/checkpoints_all\n",
      "Will store results in imitation_runs/modern_stochastic/checkpoints_all/results.h5\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "taskname2dset = gen_taskname2outfile(spec)\n",
    "\n",
    "# This is where model logs are stored.\n",
    "# We will also store the evaluation here.\n",
    "checkptdir = os.path.join(spec['options']['storagedir'], spec['options']['checkpt_subdir'])\n",
    "print 'Evaluating results in {}'.format(checkptdir)\n",
    "\n",
    "results_full_path = os.path.join(checkptdir, spec['options']['results_filename'])\n",
    "print 'Will store results in {}'.format(results_full_path)\n",
    "if os.path.exists(results_full_path):\n",
    "    raise RuntimeError('Results file {} already exists'.format(results_full_path))\n",
    "\n",
    "# First, pre-determine which evaluations we have to do\n",
    "evals_to_do = []\n",
    "nonexistent_checkptfiles = []\n",
    "for task in spec['tasks']:\n",
    "    # See how well the algorithms did...\n",
    "    for alg in spec['training']['algorithms']:\n",
    "        # ...on various dataset sizes\n",
    "        for num_trajs in spec['training']['dataset_num_trajs']:\n",
    "            # for each rerun, for mean / error bars later\n",
    "            for run in range(spec['training']['runs']):\n",
    "                # Make sure the checkpoint file exists (maybe PBS dropped some jobs)\n",
    "                strid = 'alg={},task={},num_trajs={},run={}'.format(alg['name'], task['name'], num_trajs, run)\n",
    "                checkptfile = os.path.join(checkptdir, strid + '.h5')\n",
    "                if not os.path.exists(checkptfile):\n",
    "                    nonexistent_checkptfiles.append(checkptfile)\n",
    "                if checkptfile == 'imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5':\n",
    "                    evals_to_do.append((task, alg, num_trajs, run, checkptfile))\n",
    "\n",
    "#if nonexistent_checkptfiles:\n",
    "#    print 'Cannot find checkpoint files:\\n', '\\n'.join(nonexistent_checkptfiles)\n",
    "#    raise RuntimeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[({'cuts_off_on_success': False,\n",
       "   'data_subsamp_freq': 20,\n",
       "   'env': 'Hopper-v1',\n",
       "   'name': 'hopper',\n",
       "   'policy': 'expert_policies/modern/log_Hopper-v0_3.h5/snapshots/iter0000500'},\n",
       "  {'cmd': 'python scripts/imitate_mj.py --mode ga --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --favor_zero_expert_reward {cuts_off_on_success} --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log {out}\\n',\n",
       "   'name': 'ga'},\n",
       "  25,\n",
       "  0,\n",
       "  'imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5')]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evals_to_do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[95mEvaluating run 1/1: alg=ga,task=hopper,num_trajs=25,run=0\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "collected_results = []\n",
    "for i_eval, (task, alg, num_trajs, run, checkptfile) in enumerate(evals_to_do):\n",
    "    util.header('Evaluating run {}/{}: alg={},task={},num_trajs={},run={}'.format(\n",
    "        i_eval+1, len(evals_to_do), alg['name'], task['name'], num_trajs, run))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cuts_off_on_success': False,\n",
       " 'data_subsamp_freq': 20,\n",
       " 'env': 'Hopper-v1',\n",
       " 'name': 'hopper',\n",
       " 'policy': 'expert_policies/modern/log_Hopper-v0_3.h5/snapshots/iter0000500'}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'imitation_runs/modern_stochastic/trajs/trajs_hopper.h5'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "taskname2dset[task['name']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "taskname2dset[task['name']] = 'imitation_runs/modern_stochastic/trajs/trajs_hopper.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "checkptfile = 'imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "with h5py.File(taskname2dset[task['name']], 'r') as trajf:\n",
    "    # Expert's true return and traj lengths\n",
    "    ex_traj_returns = trajf['r_B_T'][...].sum(axis=1)\n",
    "    ex_traj_lengths = trajf['len_B'][...]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3600.85445404,  3593.59654845,  3597.21851935,  3608.1891969 ,\n",
       "        3608.3514956 ,  3600.76942597,  3569.24886298,  3592.20780256,\n",
       "        3603.65330353,  3565.55785808,  3610.86397149,  3588.87158289,\n",
       "        3611.97644071,  3602.31506325,  2708.99340777,  3611.81577382,\n",
       "        3596.76356634,  3571.606662  ,  3560.50301102,  3603.85814728,\n",
       "        3587.46706745,  3591.32415659,  3596.71503242,  3589.61325206,\n",
       "        3602.19630788,  3624.32164267,  3578.48811349,  3585.01101376,\n",
       "        3598.42751121,  3618.6025666 ,  3571.13502982,  3576.87113557,\n",
       "        3605.17074857,  3583.68594682,  3604.49595658,  3608.20571546,\n",
       "        3623.89661819,  3603.75170096,  3583.24676243,  3600.82721793,\n",
       "        3573.94252232,  3598.8362137 ,  3599.59836232,  3606.74182361,\n",
       "        3599.07646239,  3603.15528772,  3605.62355385,  3631.95912756,\n",
       "        3590.98805243,  3609.8550191 ,  3599.61206318])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_traj_returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "       1000, 1000, 1000,  744, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "       1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000, 1000,\n",
       "       1000, 1000, 1000, 1000, 1000, 1000, 1000], dtype=int32)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_traj_lengths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cmd': 'python scripts/imitate_mj.py --mode ga --env {env} --data {dataset} --limit_trajs {num_trajs} --data_subsamp_freq {data_subsamp_freq} --favor_zero_expert_reward {cuts_off_on_success} --min_total_sa 50000 --max_iter 501 --reward_include_time 0 --reward_lr .01 --log {out}\\n',\n",
       " 'name': 'ga'}"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "alg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_trained_policy_and_mdp(env_name, policy_state_str):\n",
    "    import gym\n",
    "    import policyopt\n",
    "    from policyopt import nn, rl\n",
    "    from environments import rlgymenv\n",
    "\n",
    "    # Load the saved state\n",
    "    policy_file, policy_key = util.split_h5_name(policy_state_str)\n",
    "    print 'Loading policy parameters from %s in %s' % (policy_key, policy_file)\n",
    "    with h5py.File(policy_file, 'r') as f:\n",
    "        train_args = json.loads(f.attrs['args'])\n",
    "\n",
    "    # Initialize the MDP\n",
    "    print 'Loading environment', env_name\n",
    "    mdp = rlgymenv.RLGymMDP(env_name)\n",
    "    print 'MDP observation space, action space sizes: %d, %d\\n' % (mdp.obs_space.dim, mdp.action_space.storage_size)\n",
    "\n",
    "    # Initialize the policy\n",
    "    nn.reset_global_scope()\n",
    "    enable_obsnorm = bool(train_args['enable_obsnorm']) if 'enable_obsnorm' in train_args else train_args['obsnorm_mode'] != 'none'\n",
    "    if isinstance(mdp.action_space, policyopt.ContinuousSpace):\n",
    "        policy_cfg = rl.GaussianPolicyConfig(\n",
    "            hidden_spec=train_args['policy_hidden_spec'],\n",
    "            min_stdev=0.,\n",
    "            init_logstdev=0.,\n",
    "            enable_obsnorm=enable_obsnorm)\n",
    "        policy = rl.GaussianPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GaussianPolicy')\n",
    "    else:\n",
    "        policy_cfg = rl.GibbsPolicyConfig(\n",
    "            hidden_spec=train_args['policy_hidden_spec'],\n",
    "            enable_obsnorm=enable_obsnorm)\n",
    "        policy = rl.GibbsPolicy(policy_cfg, mdp.obs_space, mdp.action_space, 'GibbsPolicy')\n",
    "\n",
    "    # Load the policy parameters\n",
    "    policy.load_h5(policy_file, policy_key)\n",
    "\n",
    "    return mdp, policy, train_args\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def exec_saved_policy(env_name, policystr, num_trajs, deterministic, max_traj_len=None):\n",
    "    import policyopt\n",
    "    from policyopt import SimConfig, rl, util, nn, tqdm\n",
    "    from environments import rlgymenv\n",
    "    import gym\n",
    "\n",
    "    # Load MDP and policy\n",
    "    mdp, policy, _ = load_trained_policy_and_mdp(env_name, policystr)\n",
    "    max_traj_len = min(mdp.env_spec.timestep_limit, max_traj_len) if max_traj_len is not None else mdp.env_spec.timestep_limit\n",
    "\n",
    "    print 'Sampling {} trajs (max len {}) from policy {} in {}'.format(num_trajs, max_traj_len, policystr, env_name)\n",
    "\n",
    "    # Sample trajs\n",
    "    trajbatch = mdp.sim_mp(\n",
    "        policy_fn=lambda obs_B_Do: policy.sample_actions(obs_B_Do, deterministic),\n",
    "        obsfeat_fn=lambda obs:obs,\n",
    "        cfg=policyopt.SimConfig(\n",
    "            min_num_trajs=num_trajs,\n",
    "            min_total_sa=-1,\n",
    "            batch_size=None,\n",
    "            max_traj_len=max_traj_len))\n",
    "\n",
    "    return trajbatch, policy, mdp\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def eval_snapshot(env_name, checkptfile, snapshot_idx, num_trajs, deterministic):\n",
    "    policystr = '{}/snapshots/iter{:07d}'.format(checkptfile, snapshot_idx)\n",
    "    trajbatch, _, _ = exec_saved_policy(\n",
    "        env_name,\n",
    "        policystr,\n",
    "        num_trajs,\n",
    "        deterministic=deterministic,\n",
    "        max_traj_len=None)\n",
    "    returns = trajbatch.r.padded(fill=0.).sum(axis=1)\n",
    "    lengths = np.array([len(traj) for traj in trajbatch])\n",
    "    util.header('{} gets return {} +/- {}'.format(policystr, returns.mean(), returns.std()))\n",
    "    return returns, lengths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading policy parameters from /snapshots/iter0000500 in imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5\n",
      "Loading environment Hopper-v1\n",
      "Gym version: 0.9.1\n",
      "MDP observation space, action space sizes: 11, 3\n",
      "\n",
      "\u001b[95mLoading feedforward net specification\u001b[0m\n",
      "[\n",
      "  {\n",
      "    \"type\": \"fc\",\n",
      "    \"n\": 100\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"nonlin\",\n",
      "    \"func\": \"tanh\"\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"fc\",\n",
      "    \"n\": 100\n",
      "  },\n",
      "  {\n",
      "    \"type\": \"nonlin\",\n",
      "    \"func\": \"tanh\"\n",
      "  }\n",
      "]\n",
      "\u001b[95mAffine(in=11, out=100)\u001b[0m\n",
      "\u001b[95mNonlinearity(func=tanh)\u001b[0m\n",
      "\u001b[95mAffine(in=100, out=100)\u001b[0m\n",
      "\u001b[95mNonlinearity(func=tanh)\u001b[0m\n",
      "\u001b[95mAffine(in=100, out=3)\u001b[0m\n",
      "Reading GaussianPolicy/logstdevs_1_Da\n",
      "Reading GaussianPolicy/obsnorm/Standardizer/count\n",
      "Reading GaussianPolicy/obsnorm/Standardizer/mean_1_D\n",
      "Reading GaussianPolicy/obsnorm/Standardizer/meansq_1_D\n",
      "Reading GaussianPolicy/hidden/FeedforwardNet/layer_0/AffineLayer/W\n",
      "Reading GaussianPolicy/hidden/FeedforwardNet/layer_0/AffineLayer/b\n",
      "Reading GaussianPolicy/hidden/FeedforwardNet/layer_2/AffineLayer/W\n",
      "Reading GaussianPolicy/hidden/FeedforwardNet/layer_2/AffineLayer/b\n",
      "Reading GaussianPolicy/out/AffineLayer/W\n",
      "Reading GaussianPolicy/out/AffineLayer/b\n",
      "Sampling 50 trajs (max len 1000) from policy imitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5/snapshots/iter0000500 in Hopper-v1\n",
      "\u001b[95mimitation_runs/modern_stochastic/checkpoints_all/alg=ga,task=hopper,num_trajs=25,run=0.h5/snapshots/iter0000500 gets return 3580.92889666 +/- 4.61723660779\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Load the checkpoint file\n",
    "with pd.HDFStore(checkptfile, 'r') as f:\n",
    "    log_df = f['log']\n",
    "    log_df.set_index('iter', inplace=True)\n",
    "\n",
    "    # Evaluate true return for the learned policy\n",
    "    if alg['name'] == 'bclone':\n",
    "        # Pick the policy with the best validation accuracy\n",
    "        best_snapshot_idx = log_df['valacc'].argmax()\n",
    "        alg_traj_returns, alg_traj_lengths = eval_snapshot(\n",
    "            task['env'], checkptfile, best_snapshot_idx,\n",
    "            spec['options']['eval_num_trajs'], deterministic=True)\n",
    "\n",
    "    elif any(alg['name'].startswith(s) for s in ('ga', 'fem', 'simplex')):\n",
    "        # Evaluate the last saved snapshot\n",
    "        snapshot_names = f.root.snapshots._v_children.keys()\n",
    "        assert all(name.startswith('iter') for name in snapshot_names)\n",
    "        snapshot_inds = sorted([int(name[len('iter'):]) for name in snapshot_names])\n",
    "        best_snapshot_idx = snapshot_inds[-1]\n",
    "        alg_traj_returns, alg_traj_lengths = eval_snapshot(\n",
    "            task['env'], checkptfile, best_snapshot_idx,\n",
    "            spec['options']['eval_num_trajs'], deterministic=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collected_results.append({\n",
    "    # Trial info\n",
    "    'alg': alg['name'],\n",
    "    'task': task['name'],\n",
    "    'num_trajs': num_trajs,\n",
    "    'run': run,\n",
    "    # Expert performance\n",
    "    'ex_traj_returns': ex_traj_returns,\n",
    "    'ex_traj_lengths': ex_traj_lengths,\n",
    "    # Learned policy performance\n",
    "    'alg_traj_returns': alg_traj_returns,\n",
    "    'alg_traj_lengths': alg_traj_lengths,\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "collected_results = pd.DataFrame(collected_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg</th>\n",
       "      <th>alg_traj_lengths</th>\n",
       "      <th>alg_traj_returns</th>\n",
       "      <th>ex_traj_lengths</th>\n",
       "      <th>ex_traj_returns</th>\n",
       "      <th>num_trajs</th>\n",
       "      <th>run</th>\n",
       "      <th>task</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ga</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 1000, 1000, 1000, 100...</td>\n",
       "      <td>[3584.7193234, 3576.74629321, 3579.24360482, 3...</td>\n",
       "      <td>[1000, 1000, 1000, 1000, 1000, 1000, 1000, 100...</td>\n",
       "      <td>[3600.85445404, 3593.59654845, 3597.21851935, ...</td>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>hopper</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  alg                                   alg_traj_lengths  \\\n",
       "0  ga  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 100...   \n",
       "\n",
       "                                    alg_traj_returns  \\\n",
       "0  [3584.7193234, 3576.74629321, 3579.24360482, 3...   \n",
       "\n",
       "                                     ex_traj_lengths  \\\n",
       "0  [1000, 1000, 1000, 1000, 1000, 1000, 1000, 100...   \n",
       "\n",
       "                                     ex_traj_returns  num_trajs  run    task  \n",
       "0  [3600.85445404, 3593.59654845, 3597.21851935, ...         25    0  hopper  "
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alg_traj_returns</th>\n",
       "      <th>ex_traj_returns</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[3584.7193234, 3576.74629321, 3579.24360482, 3...</td>\n",
       "      <td>[3600.85445404, 3593.59654845, 3597.21851935, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    alg_traj_returns  \\\n",
       "0  [3584.7193234, 3576.74629321, 3579.24360482, 3...   \n",
       "\n",
       "                                     ex_traj_returns  \n",
       "0  [3600.85445404, 3593.59654845, 3597.21851935, ...  "
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collected_results[['alg_traj_returns', 'ex_traj_returns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
